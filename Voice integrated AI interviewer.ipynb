{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asif123raja/ASIF/blob/main/Voice%20integrated%20AI%20interviewer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL6Vt2cQBfRH",
        "outputId": "00a39b82-0bd7-4111-9627-c739b72a74d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Welcome to the AI Chatbot!\n",
            "Type your question (or type 'exit' to quit):\n",
            "\n",
            "You: exit\n",
            "👋 Goodbye!\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDBY4KuPsMc46zF4OJ2wvJBGWxor2bIOHc\")\n",
        "\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
        "\n",
        "\n",
        "def get_chatbot_response(prompt):\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "print(\"🤖 Welcome to the AI Chatbot!\")\n",
        "print(\"Type your question (or type 'exit' to quit):\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in ['exit', 'quit']:\n",
        "        print(\"👋 Goodbye!\")\n",
        "        break\n",
        "    response = get_chatbot_response(user_input)\n",
        "    print(\"AI Assistant:\", response)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "omE-aPERBeIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdfbf31-16e9-4262-e220-66fec391c408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m839.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ96IL9Vp71N",
        "outputId": "52949920-b6eb-4a33-9a0c-40e2cd52b783"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 154MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/abcd.opus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "eH5qlUZrp_Xt",
        "outputId": "fcbac2ca-930a-45d9-9bba-c8b31fa75e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/ogg;base64,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\" type=\"audio/ogg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load audio and pad/trim it to fit 30 seconds\n",
        "audio = whisper.load_audio(\"/content/interview.opus\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "# make log-Mel spectrogram and move to the same device as the model\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# detect the spoken language\n",
        "_, probs = model.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "# decode the audio\n",
        "options = whisper.DecodingOptions()\n",
        "result = whisper.decode(model, mel, options)\n",
        "\n",
        "# print the recognized text\n",
        "print(result.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "Ye4lrkksqCAU",
        "outputId": "ab7a3513-e8be-4348-9c52-05de21f3452d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n/content/interview.opus: No such file or directory\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/audio.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', '/content/interview.opus', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b76fd5f906e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load audio and pad/trim it to fit 30 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/interview.opus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_or_trim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# make log-Mel spectrogram and move to the same device as the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/audio.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to load audio: {e.stderr.decode()}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32768.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n/content/interview.opus: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu91mQrXqEWP",
        "outputId": "a7bd9c7a-b4b3-44fe-ac34-fa40ccc6cbdf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gtts pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6N_XnTmqGsN",
        "outputId": "e8ed8bd7-58a9-4cde-d27b-1f70fa9d461a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from gtts import gTTS\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "def transcribe2(audio):\n",
        "    # Load audio and process\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # Make log-Mel spectrogram and move to model device\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # Detect spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "    detected_lang = max(probs, key=probs.get)\n",
        "    print(f\"Detected language: {detected_lang}\")\n",
        "\n",
        "    # Decode audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    text = result.text\n",
        "\n",
        "    # Convert text to speech\n",
        "    tts = gTTS(text, lang=detected_lang)\n",
        "    tts.save(\"output.mp3\")\n",
        "\n",
        "    # Play the audio\n",
        "    audio = AudioSegment.from_file(\"output.mp3\", format=\"mp3\")\n",
        "    play(audio)\n",
        "\n",
        "    return text, \"output.mp3\"  # Returns both text and the saved audio file\n",
        "\n"
      ],
      "metadata": {
        "id": "32dTkiT6qLLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "FViBD3sZqNQ4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "    #time.sleep(3)\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    return result.text\n"
      ],
      "metadata": {
        "id": "mDA_DANUqROb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gr.Interface(\n",
        "    title = 'OpenAI Whisper ASR Gradio Web UI',\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.Audio( type=\"filepath\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        \"textbox\"\n",
        "    ],\n",
        "    live=True).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "lvHhoUMPqTRb",
        "outputId": "a878aceb-9207-49dd-ff82-71748d17bebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f8767509321d63a2f0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f8767509321d63a2f0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    title=\"OpenAI Whisper ASR Gradio Web UI\",\n",
        "    fn=transcribe2,\n",
        "    inputs=[\n",
        "        gr.Audio(type=\"filepath\")  # Accepts audio file input\n",
        "    ],\n",
        "    outputs=[\n",
        "        \"textbox\",  # Output transcribed text\n",
        "        gr.Audio(type=\"filepath\")  # Output audio file for playback\n",
        "    ],\n",
        "    live=True\n",
        ").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "k97jqK_dqVtn",
        "outputId": "7428865a-3396-4075-8fd4-eba9f88a04d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dea4c63543f4c82d1f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dea4c63543f4c82d1f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import whisper\n",
        "from gtts import gTTS\n",
        "import gradio as gr\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# === Configure Gemini API ===\n",
        "genai.configure(api_key=\"AIzaSyDBY4KuPsMc46zF4OJ2wvJBGWxor2bIOHc\")\n",
        "gemini_model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
        "\n",
        "# === Load Whisper model ===\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "# === Function 1: Transcribe Audio ===\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        # Load and process audio\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        text = result[\"text\"]\n",
        "\n",
        "        # Detect language (using the first segment's language)\n",
        "        detected_lang = result[\"language\"] if \"language\" in result else \"en\"\n",
        "        print(f\"Detected language: {detected_lang}\")\n",
        "\n",
        "        return text, detected_lang\n",
        "    except Exception as e:\n",
        "        print(f\"Transcription error: {str(e)}\")\n",
        "        return f\"Transcription error: {str(e)}\", \"en\"\n",
        "\n",
        "# === Function 2: Gemini Response ===\n",
        "def get_chatbot_response(prompt):\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# === Function 3: Text to Speech ===\n",
        "def text_to_speech(text, lang):\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as fp:\n",
        "            tts = gTTS(text=text, lang=lang)\n",
        "            tts.save(fp.name)\n",
        "            return fp.name\n",
        "    except Exception as e:\n",
        "        print(f\"TTS error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# === Main Pipeline Function ===\n",
        "def chat_pipeline(audio_path):\n",
        "    if audio_path is None:\n",
        "        return \"Please provide audio input\", None\n",
        "\n",
        "    # Step 1: Transcribe audio\n",
        "    transcribed_text, detected_lang = transcribe_audio(audio_path)\n",
        "    if transcribed_text.startswith(\"Transcription error\"):\n",
        "        return transcribed_text, None\n",
        "\n",
        "    # Step 2: Get Gemini response\n",
        "    ai_response = get_chatbot_response(transcribed_text)\n",
        "\n",
        "    # Step 3: Convert response to speech\n",
        "    speech_path = text_to_speech(ai_response, detected_lang)\n",
        "\n",
        "    return ai_response, speech_path if speech_path else None\n",
        "\n",
        "# === Gradio UI ===\n",
        "with gr.Blocks(title=\"🎤 Whisper + Gemini Voice Chatbot\") as demo:\n",
        "    gr.Markdown(\"# 🎤 Whisper + Gemini Voice Chatbot\")\n",
        "    gr.Markdown(\"Speak to the AI and get a voice response!\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            audio_input = gr.Audio(\n",
        "                sources=[\"microphone\", \"upload\"],\n",
        "                type=\"filepath\",\n",
        "                label=\"Speak or upload audio\"\n",
        "            )\n",
        "            submit_btn = gr.Button(\"Submit\")\n",
        "\n",
        "        with gr.Column():\n",
        "            text_output = gr.Textbox(label=\"AI Response\")\n",
        "            audio_output = gr.Audio(label=\"AI Voice Reply\", autoplay=True)\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=chat_pipeline,\n",
        "        inputs=audio_input,\n",
        "        outputs=[text_output, audio_output]\n",
        "    )\n",
        "\n",
        "    # Also process when audio is submitted\n",
        "    audio_input.change(\n",
        "        fn=chat_pipeline,\n",
        "        inputs=audio_input,\n",
        "        outputs=[text_output, audio_output]\n",
        "    )\n",
        "\n",
        "# Removed the conditional since it's not needed in a notebook environment.\n",
        "# The demo.launch() call should now execute when the cell is run.\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "9ux2Qm5JqdDB",
        "outputId": "5f02c12f-b73b-4d83-d9cd-e44a0e48dbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://6ff865037da8c52462.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6ff865037da8c52462.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import whisper\n",
        "from gtts import gTTS\n",
        "import gradio as gr\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# === Configure Gemini API ===\n",
        "genai.configure(api_key=\"AIzaSyDBY4KuPsMc46zF4OJ2wvJBGWxor2bIOHc\")\n",
        "gemini_model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
        "\n",
        "# === Load Whisper model ===\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "# === Function 1: Transcribe Audio ===\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        # Load and process audio\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        text = result[\"text\"]\n",
        "\n",
        "        # Detect language (using the first segment's language)\n",
        "        detected_lang = result[\"language\"] if \"language\" in result else \"en\"\n",
        "        print(f\"Detected language: {detected_lang}\")\n",
        "\n",
        "        return text, detected_lang\n",
        "    except Exception as e:\n",
        "        print(f\"Transcription error: {str(e)}\")\n",
        "        return f\"Transcription error: {str(e)}\", \"en\"\n",
        "\n",
        "# === Function 2: Gemini Response ===\n",
        "def get_chatbot_response(prompt):\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# === Function 3: Text to Speech ===\n",
        "def text_to_speech(text, lang):\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as fp:\n",
        "            tts = gTTS(text=text, lang=lang)\n",
        "            tts.save(fp.name)\n",
        "            return fp.name\n",
        "    except Exception as e:\n",
        "        print(f\"TTS error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# === Main Pipeline Function ===\n",
        "def chat_pipeline(audio_path, text_input):\n",
        "    # If both inputs are empty\n",
        "    if audio_path is None and not text_input:\n",
        "        return \"Please provide either audio or text input\", None\n",
        "\n",
        "    # If text input is provided\n",
        "    if text_input:\n",
        "        detected_lang = \"en\"  # Default to English for text input\n",
        "        ai_response = get_chatbot_response(text_input)\n",
        "    else:\n",
        "        # Step 1: Transcribe audio\n",
        "        transcribed_text, detected_lang = transcribe_audio(audio_path)\n",
        "        if transcribed_text.startswith(\"Transcription error\"):\n",
        "            return transcribed_text, None\n",
        "\n",
        "        # Step 2: Get Gemini response\n",
        "        ai_response = get_chatbot_response(transcribed_text)\n",
        "\n",
        "    # Step 3: Convert response to speech\n",
        "    speech_path = text_to_speech(ai_response, detected_lang)\n",
        "\n",
        "    return ai_response, speech_path if speech_path else None\n",
        "\n",
        "# === Gradio UI ===\n",
        "with gr.Blocks(title=\"🎤 Whisper + Gemini Voice Chatbot\") as demo:\n",
        "    gr.Markdown(\"# � Whisper + Gemini Voice Chatbot\")\n",
        "    gr.Markdown(\"Speak or type to the AI and get a voice response!\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            audio_input = gr.Audio(\n",
        "                sources=[\"microphone\", \"upload\"],\n",
        "                type=\"filepath\",\n",
        "                label=\"Speak or upload audio\"\n",
        "            )\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"Or type your message here\",\n",
        "                placeholder=\"Type your message here instead of speaking...\"\n",
        "            )\n",
        "            submit_btn = gr.Button(\"Submit\")\n",
        "\n",
        "        with gr.Column():\n",
        "            text_output = gr.Textbox(label=\"AI Response\")\n",
        "            audio_output = gr.Audio(label=\"AI Voice Reply\", autoplay=True)\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=chat_pipeline,\n",
        "        inputs=[audio_input, text_input],\n",
        "        outputs=[text_output, audio_output]\n",
        "    )\n",
        "\n",
        "    # Also process when audio is submitted\n",
        "    audio_input.change(\n",
        "        fn=lambda audio: chat_pipeline(audio, \"\"),\n",
        "        inputs=audio_input,\n",
        "        outputs=[text_output, audio_output]\n",
        "    )\n",
        "\n",
        "    # Process when text is submitted (on enter)\n",
        "    text_input.submit(\n",
        "        fn=lambda text: chat_pipeline(None, text),\n",
        "        inputs=text_input,\n",
        "        outputs=[text_output, audio_output]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "1mIw8amzHH6h",
        "outputId": "3905df1a-92af-4b50-a02c-3118bd7ec1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://586d2e114aae07b905.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://586d2e114aae07b905.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: en\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa7QN4ptYL4s84tgTV4P5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}